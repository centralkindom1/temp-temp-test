# day3_rag_simulator.py
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import json
import os
import threading
import queue
import numpy as np
import concurrent.futures
from datetime import datetime
from day3_config import Config
from day3_backend import EmbeddingAdapter, DBConnector

class RAGSimulatorGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Day 3: RAG ä»¿çœŸå™¨ & å‘é‡ä»“åº“ (åŒé€šé“ç‰ˆ: Intranet/SiliconFlow)")
        self.root.geometry("1100x950")
        
        # çº¿ç¨‹é€šä¿¡é˜Ÿåˆ—
        self.msg_queue = queue.Queue()
        
        # === åç«¯ç»„ä»¶åˆå§‹åŒ– ===
        # DBConnector æ˜¯æˆ‘ä»¬çš„"ä»“åº“ç®¡ç†å‘˜"ï¼Œè´Ÿè´£è¿æ¥ rag_production.db
        self.db_conn = DBConnector()
        # Adapter æ˜¯æˆ‘ä»¬çš„"ç¿»è¯‘å®˜"ï¼Œè´Ÿè´£è°ƒç”¨ API
        self.adapter = EmbeddingAdapter(use_mock=False) 
        
        # ä»¿çœŸå™¨å†…å­˜ï¼šä» DB åŠ è½½çš„å‘é‡å’Œå…ƒæ•°æ®å°†ç¼“å­˜åœ¨è¿™é‡Œ
        self.memory_vectors = []
        
        self._init_ui()
        
        # å¯åŠ¨é˜Ÿåˆ—è½®è¯¢
        self.root.after(100, self._check_queue)
        
        # === å¯åŠ¨æ—¶è‡ªåŠ¨å°è¯•æŒ‚è½½é»˜è®¤è·¯å¾„ ===
        # è™½ç„¶å¢åŠ äº†æ‰‹åŠ¨æŒ‚è½½ï¼Œä½†ä¸ºäº†æ–¹ä¾¿ï¼Œå¯åŠ¨æ—¶è¿˜æ˜¯è‡ªåŠ¨æŒ‚è½½ä¸€æ¬¡
        self.reload_memory_db()
        
    def _init_ui(self):
        main_layout = tk.Frame(self.root)
        main_layout.pack(fill="both", expand=True)

        # ==========================================
        # åŒºåŸŸ 1ï¼šå·¥åº A - å‘é‡åŒ–å…¥åº“ (The Truck)
        # ==========================================
        ingest_frame = tk.LabelFrame(main_layout, text="å·¥åº A: å‘é‡åŒ–å…¥åº“ (Source: JSON -> Target: DB)", padx=10, pady=10)
        ingest_frame.pack(fill="x", padx=10, pady=5)
        
        # ç¬¬ä¸€è¡Œï¼šæ–‡ä»¶é€‰æ‹© (JSON æº)
        file_box = tk.Frame(ingest_frame)
        file_box.pack(fill="x", pady=2)
        tk.Label(file_box, text="[è¿è´§å¡è½¦] Day2 äº§ç‰© JSON:").pack(side="left")
        self.json_path_entry = tk.Entry(file_box, width=50)
        self.json_path_entry.pack(side="left", padx=5)
        self.json_path_entry.insert(0, Config.INPUT_JSON_PATH)
        tk.Button(file_box, text="æµè§ˆ...", command=self.browse_json_file).pack(side="left")

        # ç¬¬äºŒè¡Œï¼šAPI é…ç½®ä¸å¹¶å‘æ§åˆ¶
        config_box = tk.Frame(ingest_frame)
        config_box.pack(fill="x", pady=8)
        
        # 1. API é€‰æ‹©
        tk.Label(config_box, text="API æä¾›å•†:", font=("bold")).pack(side="left")
        self.provider_var = tk.StringVar(value="Intranet (AirChina)")
        self.provider_combo = ttk.Combobox(config_box, textvariable=self.provider_var, state="readonly", width=22)
        self.provider_combo['values'] = ("Intranet (AirChina)", "SiliconFlow (Public)")
        self.provider_combo.pack(side="left", padx=5)
        
        # 2. æ‰¹æ¬¡å¤§å°
        tk.Label(config_box, text=" |  Batch Size:").pack(side="left", padx=2)
        self.batch_size_spin = tk.Spinbox(config_box, from_=1, to=50, width=5)
        self.batch_size_spin.delete(0, "end")
        self.batch_size_spin.insert(0, Config.DEFAULT_BATCH_SIZE)
        self.batch_size_spin.pack(side="left")
        
        # 3. æœ€å¤§å¹¶å‘
        tk.Label(config_box, text=" |  Max Concurrency:").pack(side="left", padx=2)
        self.concurrency_spin = tk.Spinbox(config_box, from_=1, to=10, width=5)
        self.concurrency_spin.delete(0, "end")
        self.concurrency_spin.insert(0, Config.DEFAULT_CONCURRENCY)
        self.concurrency_spin.pack(side="left")

        # 4. å¯åŠ¨æŒ‰é’®
        self.btn_ingest = tk.Button(config_box, text="ğŸš€ å¯åŠ¨æ‰¹é‡å‘é‡åŒ–å…¥åº“", bg="#007ACC", fg="white", font=("Arial", 10, "bold"), command=self.start_ingestion_thread)
        self.btn_ingest.pack(side="left", padx=20)
        
        # è¿›åº¦æ¡
        self.progress_bar = ttk.Progressbar(ingest_frame, orient="horizontal", length=400, mode="determinate")
        self.progress_bar.pack(fill="x", padx=5, pady=5)

        # ==========================================
        # åŒºåŸŸ 2ï¼šå·¥åº B - RAG ä»¿çœŸéªŒè¯ (The Warehouse)
        # ==========================================
        sim_frame = tk.LabelFrame(main_layout, text="å·¥åº B: RAG ä»¿çœŸéªŒè¯ (Source: DB Warehouse)", padx=10, pady=10)
        sim_frame.pack(fill="both", expand=True, padx=10, pady=5)
        
        # --- æ–°å¢ï¼šæ•°æ®åº“æ‰‹åŠ¨æŒ‚è½½æ§åˆ¶åŒº ---
        db_control_box = tk.Frame(sim_frame, bg="#f0f0f0", bd=1, relief="groove")
        db_control_box.pack(fill="x", pady=5, padx=5)
        
        tk.Label(db_control_box, text="[ç¨³å›ºä»“åº“] DBæ–‡ä»¶è·¯å¾„:", bg="#f0f0f0").pack(side="left", padx=5)
        self.db_path_entry = tk.Entry(db_control_box, width=50)
        self.db_path_entry.pack(side="left", padx=5, pady=5)
        self.db_path_entry.insert(0, Config.DB_PATH) # é»˜è®¤å¡«å…¥ Config é‡Œçš„è·¯å¾„
        
        tk.Button(db_control_box, text="ğŸ“‚ é€‰æ‹©ä»“åº“...", command=self.browse_db_file).pack(side="left", padx=2)
        tk.Button(db_control_box, text="ğŸ”„ ç«‹å³æŒ‚è½½/åˆ·æ–°", bg="#ffc107", command=self.reload_memory_db).pack(side="left", padx=10)
        
        # çŠ¶æ€æ˜¾ç¤ºæ ‡ç­¾
        self.db_status_label = tk.Label(db_control_box, text="çŠ¶æ€: ç­‰å¾…æŒ‚è½½...", bg="#f0f0f0", fg="#666666", font=("Consolas", 9, "bold"))
        self.db_status_label.pack(side="left", padx=10)
        
        # --- æœç´¢åŒºåŸŸ ---
        search_box = tk.Frame(sim_frame)
        search_box.pack(fill="x", pady=10)
        tk.Label(search_box, text="è¾“å…¥æµ‹è¯•é—®é¢˜:", font=("Arial", 12, "bold")).pack(side="left")
        self.query_entry = tk.Entry(search_box, font=("Arial", 12))
        self.query_entry.pack(side="left", fill="x", expand=True, padx=10)
        self.query_entry.bind("<Return>", lambda event: self.run_simulation())
        
        btn_search = tk.Button(search_box, text="ğŸ” è®¡ç®—ç›¸ä¼¼åº¦å¬å›", bg="#28a745", fg="white", font=("Arial", 11, "bold"), command=self.run_simulation)
        btn_search.pack(side="left")

        # ç»“æœæ˜¾ç¤ºåŒº
        self.result_area = scrolledtext.ScrolledText(sim_frame, font=("Segoe UI", 10), height=15)
        self.result_area.pack(fill="both", expand=True)
        
        # æ ·å¼é…ç½®
        self.result_area.tag_config("title_hit", background="yellow", foreground="black", font=("Segoe UI", 10, "bold"))
        self.result_area.tag_config("score", foreground="red", font=("Segoe UI", 10, "bold"))
        self.result_area.tag_config("meta", foreground="#666666", font=("Consolas", 9))
        self.result_area.tag_config("source_db", foreground="blue", font=("Consolas", 8, "italic"))
        self.result_area.tag_config("pure_body", foreground="black", font=("Segoe UI", 10))

        # ==========================================
        # åŒºåŸŸ 3ï¼šå®æ—¶æ§åˆ¶å°æ—¥å¿—
        # ==========================================
        console_frame = tk.LabelFrame(main_layout, text="åå°é€šè®¯æ—¥å¿— (Console Log)", padx=10, pady=5, bg="#1e1e1e", fg="white")
        console_frame.pack(fill="x", padx=10, pady=5, side="bottom")
        
        self.console_area = scrolledtext.ScrolledText(console_frame, height=8, bg="black", fg="#00FF00", font=("Consolas", 9))
        self.console_area.pack(fill="both", expand=True)

    def log(self, msg):
        """çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å‘é€æ–¹æ³•"""
        self.msg_queue.put(("LOG", msg))

    def _check_queue(self):
        """ä¸»çº¿ç¨‹è½®è¯¢é˜Ÿåˆ—ï¼Œæ›´æ–° GUI"""
        try:
            while True:
                msg_type, content = self.msg_queue.get_nowait()
                
                if msg_type == "LOG":
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    self.console_area.insert(tk.END, f"[{timestamp}] {content}\n")
                    self.console_area.see(tk.END)
                
                elif msg_type == "PROGRESS":
                    self.progress_bar['value'] = content
                
                elif msg_type == "STATUS_DONE":
                    messagebox.showinfo("å®Œæˆ", content)
                    self.btn_ingest.config(state="normal")
                    # å…¥åº“å®Œæˆåï¼Œè‡ªåŠ¨åˆ·æ–°
                    self.reload_memory_db() 
                
                elif msg_type == "ERROR":
                    messagebox.showerror("é”™è¯¯", content)
                    self.btn_ingest.config(state="normal")
                
        except queue.Empty:
            pass
        finally:
            self.root.after(100, self._check_queue)

    # --- æ–‡ä»¶é€‰æ‹©è¾…åŠ© ---
    def browse_json_file(self):
        fn = filedialog.askopenfilename(filetypes=[("JSON Files", "*.json")])
        if fn: 
            self.json_path_entry.delete(0, tk.END)
            self.json_path_entry.insert(0, fn)

    def browse_db_file(self):
        fn = filedialog.askopenfilename(filetypes=[("SQLite DB", "*.db"), ("All Files", "*.*")])
        if fn:
            self.db_path_entry.delete(0, tk.END)
            self.db_path_entry.insert(0, fn)
            # é€‰å®Œæ–‡ä»¶åï¼Œè‡ªåŠ¨è§¦å‘ä¸€æ¬¡æŒ‚è½½ï¼Œæå‡ä½“éªŒ
            self.reload_memory_db()

    def get_current_api_config(self):
        """æ ¹æ®ä¸‹æ‹‰æ¡†é€‰æ‹©è·å–é…ç½®"""
        choice = self.provider_var.get()
        if "SiliconFlow" in choice:
            return {
                "name": "SiliconFlow",
                "url": Config.SILICON_API_URL,
                "key": Config.SILICON_API_KEY,
                "model": Config.SILICON_MODEL_NAME
            }
        else:
            return {
                "name": "Intranet",
                "url": Config.INTRANET_API_URL,
                "key": Config.INTRANET_API_KEY,
                "model": Config.INTRANET_MODEL_NAME
            }

    # --- æ ¸å¿ƒé€»è¾‘ï¼šä»æ•°æ®åº“(ä»“åº“)åŠ è½½æ•°æ® ---
    def reload_memory_db(self):
        """
        è¿æ¥ DBï¼Œæ‹‰å– embedding_json, full_context_text å’Œ pure_text åˆ°å†…å­˜ã€‚
        æ”¯æŒä» UI è¾“å…¥æ¡†åŠ¨æ€è¯»å– DB è·¯å¾„ã€‚
        """
        # 1. è·å–ç•Œé¢ä¸Šé…ç½®çš„ DB è·¯å¾„
        target_db_path = self.db_path_entry.get().strip()
        if not target_db_path:
            target_db_path = Config.DB_PATH # å›é€€åˆ°é»˜è®¤
        
        self.log(f"æ­£åœ¨å°è¯•æŒ‚è½½æ•°æ®åº“: {target_db_path} ...")
        
        # 2. æ›´æ–° Connector çš„è·¯å¾„
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åŠ¨æ€ä¿®æ”¹ db_conn å®ä¾‹çš„è·¯å¾„å±æ€§ï¼Œä»¥ä¾¿åç»­æ“ä½œéƒ½é’ˆå¯¹æ–° DB
        self.db_conn.db_path = target_db_path
        
        if not os.path.exists(target_db_path):
            self.log(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {target_db_path}")
            self.db_status_label.config(text=f"çŠ¶æ€: æ–‡ä»¶ä¸å­˜åœ¨", fg="red")
            self.memory_vectors = []
            return

        # 3. è°ƒç”¨ Backend çš„æ–¹æ³•
        # æ­¤æ—¶ db_conn.fetch_all_vectors() å†…éƒ¨ä¼šä½¿ç”¨ self.db_path (ä¹Ÿå°±æ˜¯æˆ‘ä»¬åˆšæ‰è®¾ç½®çš„ target_db_path)
        raw_data = self.db_conn.fetch_all_vectors()
        
        if not raw_data:
            self.log("æŒ‚è½½æˆåŠŸï¼Œä½†æ•°æ®åº“ä¸ºç©º (æ²¡æœ‰æœ‰æ•ˆå‘é‡)ã€‚")
            self.memory_vectors = []
            self.db_status_label.config(text=f"çŠ¶æ€: ç©ºæ•°æ®åº“ | Path: {os.path.basename(target_db_path)}", fg="#ff8800")
            return

        # 4. è½¬æ¢æ•°æ®æ ¼å¼
        self.memory_vectors = []
        for item in raw_data:
            try:
                item['np_vector'] = np.array(item['vector'])
                self.memory_vectors.append(item)
            except Exception as e:
                print(f"Skipping bad vector: {e}")
            
        count = len(self.memory_vectors)
        self.log(f"æ•°æ®åº“æŒ‚è½½æˆåŠŸï¼å†…å­˜ç´¢å¼•å·²æ„å»ºï¼Œå…± {count} æ¡æ•°æ®ã€‚")
        self.db_status_label.config(text=f"çŠ¶æ€: å·²æŒ‚è½½ âœ… | ç´¢å¼•é‡: {count} æ¡", fg="green")

    # --- çº¿ç¨‹å·¥ä½œé€»è¾‘ï¼šå…¥åº“ (JSON -> API -> DB) ---
    def start_ingestion_thread(self):
        path = self.json_path_entry.get()
        if not os.path.exists(path):
            messagebox.showerror("é”™è¯¯", "æ‰¾ä¸åˆ°è¾“å…¥çš„ JSON æ–‡ä»¶")
            return
        
        try:
            batch_size = int(self.batch_size_spin.get())
            max_workers = int(self.concurrency_spin.get())
            if batch_size < 1 or max_workers < 1: raise ValueError
        except:
            messagebox.showerror("é”™è¯¯", "æ‰¹æ¬¡å¤§å°æˆ–å¹¶å‘æ•°å¿…é¡»ä¸ºæ­£æ•´æ•°")
            return

        api_config = self.get_current_api_config()
        
        self.btn_ingest.config(state="disabled")
        self.log(f"å¯åŠ¨å…¥åº“ä»»åŠ¡ | æº: JSON | ç›®æ ‡: DB | å¹¶å‘: {max_workers}")
        
        threading.Thread(
            target=self.run_ingestion, 
            args=(path, api_config, batch_size, max_workers), 
            daemon=True
        ).start()

    def run_ingestion(self, json_path, api_config, batch_size, max_workers):
        try:
            self.log("æ­£åœ¨è§£æ JSON æ–‡ä»¶...")
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            total_items = len(data)
            self.log(f"è§£ææˆåŠŸï¼Œå…± {total_items} æ¡æ•°æ®å¾…å¤„ç†ã€‚")
            
            batches = []
            for i in range(0, total_items, batch_size):
                batch_data = data[i:i+batch_size]
                batch_texts = [item['embedding_text'] for item in batch_data]
                batches.append({
                    'index': i,
                    'data': batch_data,
                    'texts': batch_texts
                })
            
            processed_data = []
            processed_count = 0
            lock = threading.Lock()
            
            def process_batch(batch_info):
                texts = batch_info['texts']
                def thread_logger(msg):
                    if "Error" in msg: self.log(msg)
                
                try:
                    vectors = self.adapter.get_embeddings(texts, provider_config=api_config, logger=thread_logger)
                    
                    result_records = []
                    for idx, item in enumerate(batch_info['data']):
                        meta = item.get('metadata', {})
                        path_list = meta.get('section_path', [])
                        h1 = path_list[1] if len(path_list) > 1 else ""
                        h2 = path_list[2] if len(path_list) > 2 else ""
                        
                        record = item.copy()
                        record['embedding'] = vectors[idx]
                        record['chapter_title_temp'] = h1
                        record['sub_title_temp'] = h2
                        
                        raw_content = item.get('embedding_text', "")
                        if "Content: " in raw_content:
                            pure = raw_content.split("Content: ", 1)[1]
                        else:
                            pure = raw_content
                        meta['pure_text_temp'] = pure
                        
                        result_records.append(record)
                    return result_records
                except Exception as e:
                    self.log(f"[Batch Error] ç´¢å¼• {batch_info['index']} å¤±è´¥: {e}")
                    return None

            self.log(f"å¼€å§‹å¹¶å‘å¤„ç†ï¼Œçº¿ç¨‹æ± å¤§å°: {max_workers}")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_batch = {executor.submit(process_batch, b): b for b in batches}
                
                for future in concurrent.futures.as_completed(future_to_batch):
                    results = future.result()
                    if results:
                        with lock:
                            # è¿™é‡Œè°ƒç”¨ backend çš„ bulk_insertï¼Œæ•°æ®çœŸæ­£å­˜å…¥ Warehouse (DB)
                            # æ³¨æ„ï¼šå…¥åº“æ—¶ä½¿ç”¨çš„æ˜¯ db_conn å½“å‰çš„è·¯å¾„ï¼Œå¦‚æœåˆšæ‰ç”¨æˆ·æ”¹äº†è·¯å¾„ï¼Œå°±ä¼šå…¥åº“åˆ°æ–°æ–‡ä»¶
                            self.db_conn.bulk_insert(results)
                            processed_data.extend(results)
                            processed_count += len(results)
                            
                            progress = (processed_count / total_items) * 100
                            self.msg_queue.put(("PROGRESS", progress))
                            
                            if processed_count % (batch_size * 2) == 0:
                                self.log(f"è¿›åº¦: {processed_count}/{total_items} å·²å…¥åº“")
            
            self.log("å…¥åº“ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼æ•°æ®å·²å®‰å…¨å­˜å…¥æ•°æ®åº“ã€‚")
            self.msg_queue.put(("STATUS_DONE", f"å…¥åº“æˆåŠŸï¼å…± {len(processed_data)} æ¡æ•°æ®ã€‚\nå·²å­˜å…¥ DBã€‚"))
            
        except Exception as e:
            import traceback
            err = traceback.format_exc()
            self.log(f"FATAL ERROR: {str(e)}")
            print(err)
            self.msg_queue.put(("ERROR", f"å¤„ç†å¼‚å¸¸: {str(e)}"))

    # --- ä»¿çœŸæœç´¢é€»è¾‘ (Read from DB Memory) ---
    def run_simulation(self):
        query = self.query_entry.get()
        if not query: return
        
        # å¼ºåˆ¶æ£€æŸ¥ï¼šå¿…é¡»åŸºäºæ•°æ®åº“å†…å®¹
        if not self.memory_vectors:
            messagebox.showwarning("è­¦å‘Š", "å½“å‰æœªæŒ‚è½½æ•°æ®åº“æˆ–æ•°æ®åº“ä¸ºç©ºã€‚\nè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å¹¶ç‚¹å‡»'ç«‹å³æŒ‚è½½/åˆ·æ–°'")
            return

        self.result_area.configure(state="normal")
        self.result_area.delete(1.0, tk.END)
        
        api_config = self.get_current_api_config()
        self.log(f"æ­£åœ¨å‘é‡åŒ–é—®é¢˜: '{query}' ...")
        
        try:
            q_vec = self.adapter.get_embeddings([query], provider_config=api_config, logger=None)[0]
            q_vec_np = np.array(q_vec)
        except Exception as e:
            self.result_area.insert(tk.END, f"[Error] å‘é‡åŒ–å¤±è´¥: {e}\n")
            self.log(f"å‘é‡åŒ–å¤±è´¥: {e}")
            return

        self.log(f"æ­£åœ¨ {len(self.memory_vectors)} æ¡æ•°æ®ä¸­æ£€ç´¢ (ä½™å¼¦ç›¸ä¼¼åº¦)...")
        scores = []
        q_norm = np.linalg.norm(q_vec_np)
        
        # è¿™é‡Œçš„ item æ¥æºäº reload_memory_db ä¸­æ‹‰å–çš„ DB æ•°æ®
        for item in self.memory_vectors:
            d_vec_np = item['np_vector']
            d_norm = np.linalg.norm(d_vec_np)
            
            if q_norm == 0 or d_norm == 0:
                sim = 0
            else:
                sim = np.dot(q_vec_np, d_vec_np) / (q_norm * d_norm)
            
            scores.append((sim, item))

        scores.sort(key=lambda x: x[0], reverse=True)
        top_k = scores[:3]

        self.result_area.insert(tk.END, f"\n{'='*20} ä»¿çœŸå¬å›ç»“æœ (Top 3) {'='*20}\n")
        
        current_db_name = os.path.basename(self.db_path_entry.get())
        self.result_area.insert(tk.END, f"æ•°æ®æº: {current_db_name} (Pure Text Fusion)\n\n", "source_db")
        
        if not top_k:
            self.result_area.insert(tk.END, "æ— åŒ¹é…ç»“æœã€‚\n")

        for i, (score, item) in enumerate(top_k):
            self.log(f"Top {i+1} Score: {score:.4f} | Doc: {item['doc']}")
            
            self.result_area.insert(tk.END, f"Rank {i+1} | ")
            self.result_area.insert(tk.END, f"ç›¸ä¼¼åº¦: {score:.4f}\n", "score")
            
            # 1. æ ‡é¢˜
            title_text = f"æ–‡æ¡£: {item['doc']} >> ç« : {item['chapter']} >> èŠ‚: {item['sub']}\n"
            self.result_area.insert(tk.END, title_text, "title_hit")
            
            # 2. èåˆå†…å®¹å±•ç¤º (Full Context Header + Pure Text Body)
            full_context = item['text']
            pure_text_body = item.get('pure_text', "")
            
            # æå– Header (åŒ…å«è·¯å¾„ä¿¡æ¯çš„éƒ¨åˆ†)
            header_text = ""
            if "Content: " in full_context:
                header_text = full_context.split("Content: ", 1)[0] + "Content: "
            else:
                header_text = "Metadata Header (Parse Failed):"

            # æ˜¾ç¤º Header
            self.result_area.insert(tk.END, f"[Full Context Header]:\n{header_text}\n", "meta")
            
            # æ˜¾ç¤º Body (ä¼˜å…ˆä½¿ç”¨ Pure Textï¼Œå›é€€åˆ°åˆ†å‰²æ³•)
            if pure_text_body and len(pure_text_body.strip()) > 0:
                 self.result_area.insert(tk.END, f"[Pure Text Body]:\n{pure_text_body.strip()}\n", "pure_body")
            elif "Content: " in full_context:
                 # Fallback
                 fallback_body = full_context.split("Content: ", 1)[1]
                 self.result_area.insert(tk.END, f"[Body (Fallback)]:\n{fallback_body.strip()}\n")
            else:
                 self.result_area.insert(tk.END, f"[Body]:\n{full_context}\n")

            self.result_area.insert(tk.END, "-"*50 + "\n")

        self.result_area.configure(state="disabled")

if __name__ == "__main__":
    root = tk.Tk()
    app = RAGSimulatorGUI(root)
    root.mainloop()