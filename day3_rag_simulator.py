# day3_rag_simulator.py
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import json
import os
import threading
import queue
import numpy as np
import concurrent.futures
from datetime import datetime
from day3_config import Config
from day3_backend import EmbeddingAdapter, DBConnector

class RAGSimulatorGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Day 3: RAG ä»¿çœŸå™¨ & å‘é‡ä»“åº“ (åŒé€šé“ç‰ˆ: Intranet/SiliconFlow)")
        self.root.geometry("1100x950")
        
        # çº¿ç¨‹é€šä¿¡é˜Ÿåˆ—
        self.msg_queue = queue.Queue()
        
        # === åç«¯ç»„ä»¶åˆå§‹åŒ– ===
        # DBConnector æ˜¯æˆ‘ä»¬çš„"ä»“åº“ç®¡ç†å‘˜"ï¼Œè´Ÿè´£è¿æ¥ rag_production.db
        self.db_conn = DBConnector()
        # Adapter æ˜¯æˆ‘ä»¬çš„"ç¿»è¯‘å®˜"ï¼Œè´Ÿè´£è°ƒç”¨ API
        self.adapter = EmbeddingAdapter(use_mock=False) 
        
        # ä»¿çœŸå™¨å†…å­˜ï¼šä» DB åŠ è½½çš„å‘é‡å’Œå…ƒæ•°æ®å°†ç¼“å­˜åœ¨è¿™é‡Œ
        self.memory_vectors = []
        
        self._init_ui()
        
        # å¯åŠ¨é˜Ÿåˆ—è½®è¯¢
        self.root.after(100, self._check_queue)
        
        # === å¯åŠ¨æ—¶è‡ªåŠ¨å°è¯•æŒ‚è½½é»˜è®¤è·¯å¾„ ===
        # è™½ç„¶å¢åŠ äº†æ‰‹åŠ¨æŒ‚è½½ï¼Œä½†ä¸ºäº†æ–¹ä¾¿ï¼Œå¯åŠ¨æ—¶è¿˜æ˜¯è‡ªåŠ¨æŒ‚è½½ä¸€æ¬¡
        self.reload_memory_db()
        
    def _init_ui(self):
        main_layout = tk.Frame(self.root)
        main_layout.pack(fill="both", expand=True)

        # ==========================================
        # åŒºåŸŸ 1ï¼šå·¥åº A - å‘é‡åŒ–å…¥åº“ (The Truck)
        # ==========================================
        ingest_frame = tk.LabelFrame(main_layout, text="å·¥åº A: å‘é‡åŒ–å…¥åº“ (Source: JSON -> Target: DB)", padx=10, pady=10)
        ingest_frame.pack(fill="x", padx=10, pady=5)
        
        # ç¬¬ä¸€è¡Œï¼šæ–‡ä»¶é€‰æ‹© (JSON æº)
        file_box = tk.Frame(ingest_frame)
        file_box.pack(fill="x", pady=2)
        tk.Label(file_box, text="[è¿è´§å¡è½¦] Day2 äº§ç‰© JSON:").pack(side="left")
        self.json_path_entry = tk.Entry(file_box, width=50)
        self.json_path_entry.pack(side="left", padx=5)
        self.json_path_entry.insert(0, Config.INPUT_JSON_PATH)
        tk.Button(file_box, text="æµè§ˆ...", command=self.browse_json_file).pack(side="left")

        # ç¬¬äºŒè¡Œï¼šAPI é…ç½®ä¸å¹¶å‘æ§åˆ¶
        config_box = tk.Frame(ingest_frame)
        config_box.pack(fill="x", pady=8)
        
        # 1. API é€‰æ‹©
        tk.Label(config_box, text="API æä¾›å•†:", font=("bold")).pack(side="left")
        self.provider_var = tk.StringVar(value="Intranet (AirChina)")
        self.provider_combo = ttk.Combobox(config_box, textvariable=self.provider_var, state="readonly", width=22)
        self.provider_combo['values'] = ("Intranet (AirChina)", "SiliconFlow (Public)")
        self.provider_combo.pack(side="left", padx=5)
        
        # 2. æ‰¹æ¬¡å¤§å°
        tk.Label(config_box, text=" |  Batch Size:").pack(side="left", padx=2)
        self.batch_size_spin = tk.Spinbox(config_box, from_=1, to=50, width=5)
        self.batch_size_spin.delete(0, "end")
        self.batch_size_spin.insert(0, Config.DEFAULT_BATCH_SIZE)
        self.batch_size_spin.pack(side="left")
        
        # 3. æœ€å¤§å¹¶å‘
        tk.Label(config_box, text=" |  Max Concurrency:").pack(side="left", padx=2)
        self.concurrency_spin = tk.Spinbox(config_box, from_=1, to=10, width=5)
        self.concurrency_spin.delete(0, "end")
        self.concurrency_spin.insert(0, Config.DEFAULT_CONCURRENCY)
        self.concurrency_spin.pack(side="left")

        # 4. å¯åŠ¨æŒ‰é’®
        self.btn_ingest = tk.Button(config_box, text="ğŸš€ å¯åŠ¨æ‰¹é‡å‘é‡åŒ–å…¥åº“", bg="#007ACC", fg="white", font=("Arial", 10, "bold"), command=self.start_ingestion_thread)
        self.btn_ingest.pack(side="left", padx=20)
        
        # è¿›åº¦æ¡
        self.progress_bar = ttk.Progressbar(ingest_frame, orient="horizontal", length=400, mode="determinate")
        self.progress_bar.pack(fill="x", padx=5, pady=5)

        # ==========================================
        # åŒºåŸŸ 2ï¼šå·¥åº B - RAG ä»¿çœŸéªŒè¯ (The Warehouse)
        # ==========================================
        sim_frame = tk.LabelFrame(main_layout, text="å·¥åº B: RAG ä»¿çœŸéªŒè¯ (Source: DB Warehouse)", padx=10, pady=10)
        sim_frame.pack(fill="both", expand=True, padx=10, pady=5)
        
        # --- æ–°å¢ï¼šæ•°æ®åº“æ‰‹åŠ¨æŒ‚è½½æ§åˆ¶åŒº ---
        db_control_box = tk.Frame(sim_frame, bg="#f0f0f0", bd=1, relief="groove")
        db_control_box.pack(fill="x", pady=5, padx=5)
        
        tk.Label(db_control_box, text="[ç¨³å›ºä»“åº“] DBæ–‡ä»¶è·¯å¾„:", bg="#f0f0f0").pack(side="left", padx=5)
        self.db_path_entry = tk.Entry(db_control_box, width=50)
        self.db_path_entry.pack(side="left", padx=5, pady=5)
        self.db_path_entry.insert(0, Config.DB_PATH) # é»˜è®¤å¡«å…¥ Config é‡Œçš„è·¯å¾„
        
        tk.Button(db_control_box, text="ğŸ“‚ é€‰æ‹©ä»“åº“...", command=self.browse_db_file).pack(side="left", padx=2)
        tk.Button(db_control_box, text="ğŸ”„ ç«‹å³æŒ‚è½½/åˆ·æ–°", bg="#ffc107", command=self.reload_memory_db).pack(side="left", padx=10)
        
        # çŠ¶æ€æ˜¾ç¤ºæ ‡ç­¾
        self.db_status_label = tk.Label(db_control_box, text="çŠ¶æ€: ç­‰å¾…æŒ‚è½½...", bg="#f0f0f0", fg="#666666", font=("Consolas", 9, "bold"))
        self.db_status_label.pack(side="left", padx=10)
        
        # --- æœç´¢åŒºåŸŸ ---
        search_box = tk.Frame(sim_frame)
        search_box.pack(fill="x", pady=10)
        tk.Label(search_box, text="è¾“å…¥æµ‹è¯•é—®é¢˜:", font=("Arial", 12, "bold")).pack(side="left")
        self.query_entry = tk.Entry(search_box, font=("Arial", 12))
        self.query_entry.pack(side="left", fill="x", expand=True, padx=10)
        self.query_entry.bind("<Return>", lambda event: self.run_simulation())
        
        btn_search = tk.Button(search_box, text="ğŸ” è®¡ç®—ç›¸ä¼¼åº¦å¬å›", bg="#28a745", fg="white", font=("Arial", 11, "bold"), command=self.run_simulation)
        btn_search.pack(side="left")

        # ç»“æœæ˜¾ç¤ºåŒº
        self.result_area = scrolledtext.ScrolledText(sim_frame, font=("Segoe UI", 10), height=15)
        self.result_area.pack(fill="both", expand=True)
        
        # æ ·å¼é…ç½®
        self.result_area.tag_config("title_hit", background="yellow", foreground="black", font=("Segoe UI", 10, "bold"))
        self.result_area.tag_config("score", foreground="red", font=("Segoe UI", 10, "bold"))
        self.result_area.tag_config("meta", foreground="#666666", font=("Consolas", 9))
        self.result_area.tag_config("source_db", foreground="blue", font=("Consolas", 8, "italic"))
        self.result_area.tag_config("pure_body", foreground="black", font=("Segoe UI", 10))

        # ==========================================
        # åŒºåŸŸ 3ï¼šå®æ—¶æ§åˆ¶å°æ—¥å¿—
        # ==========================================
        console_frame = tk.LabelFrame(main_layout, text="åå°é€šè®¯æ—¥å¿— (Console Log)", padx=10, pady=5, bg="#1e1e1e", fg="white")
        console_frame.pack(fill="x", padx=10, pady=5, side="bottom")
        
        self.console_area = scrolledtext.ScrolledText(console_frame, height=8, bg="black", fg="#00FF00", font=("Consolas", 9))
        self.console_area.pack(fill="both", expand=True)

    def log(self, msg):
        """çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—å‘é€æ–¹æ³•"""
        self.msg_queue.put(("LOG", msg))

    def _check_queue(self):
        """ä¸»çº¿ç¨‹è½®è¯¢é˜Ÿåˆ—ï¼Œæ›´æ–° GUI"""
        try:
            while True:
                msg_type, content = self.msg_queue.get_nowait()
                
                if msg_type == "LOG":
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    self.console_area.insert(tk.END, f"[{timestamp}] {content}\n")
                    self.console_area.see(tk.END)
                
                elif msg_type == "PROGRESS":
                    self.progress_bar['value'] = content
                
                elif msg_type == "STATUS_DONE":
                    messagebox.showinfo("å®Œæˆ", content)
                    self.btn_ingest.config(state="normal")
                    # å…¥åº“å®Œæˆåï¼Œè‡ªåŠ¨åˆ·æ–°
                    self.reload_memory_db() 
                
                elif msg_type == "ERROR":
                    messagebox.showerror("é”™è¯¯", content)
                    self.btn_ingest.config(state="normal")
                
        except queue.Empty:
            pass
        finally:
            self.root.after(100, self._check_queue)

    # --- æ–‡ä»¶é€‰æ‹©è¾…åŠ© ---
    def browse_json_file(self):
        fn = filedialog.askopenfilename(filetypes=[("JSON Files", "*.json")])
        if fn: 
            self.json_path_entry.delete(0, tk.END)
            self.json_path_entry.insert(0, fn)

    def browse_db_file(self):
        fn = filedialog.askopenfilename(filetypes=[("SQLite DB", "*.db"), ("All Files", "*.*")])
        if fn:
            self.db_path_entry.delete(0, tk.END)
            self.db_path_entry.insert(0, fn)
            # é€‰å®Œæ–‡ä»¶åï¼Œè‡ªåŠ¨è§¦å‘ä¸€æ¬¡æŒ‚è½½ï¼Œæå‡ä½“éªŒ
            self.reload_memory_db()

    def get_current_api_config(self):
        """æ ¹æ®ä¸‹æ‹‰æ¡†é€‰æ‹©è·å–é…ç½®"""
        choice = self.provider_var.get()
        if "SiliconFlow" in choice:
            return {
                "name": "SiliconFlow",
                "url": Config.SILICON_API_URL,
                "key": Config.SILICON_API_KEY,
                "model": Config.SILICON_MODEL_NAME
            }
        else:
            return {
                "name": "Intranet",
                "url": Config.INTRANET_API_URL,
                "key": Config.INTRANET_API_KEY,
                "model": Config.INTRANET_MODEL_NAME
            }

    # --- æ ¸å¿ƒé€»è¾‘ï¼šä»æ•°æ®åº“(ä»“åº“)åŠ è½½æ•°æ® ---
    def reload_memory_db(self):
        """
        âœ¨ æ–¹æ¡ˆ 2 ä¿®å¤ç‰ˆæœ¬ï¼šè¿æ¥ DBï¼Œæ‹‰å– embedding_json, full_context_text å’Œ pure_text åˆ°å†…å­˜ã€‚
        æ”¯æŒä» UI è¾“å…¥æ¡†åŠ¨æ€è¯»å– DB è·¯å¾„ã€‚
        å¢å¼ºçš„æ•°æ®éªŒè¯å’Œä¿®å¤èƒ½åŠ›ã€‚
        """
        # 1. è·å–ç•Œé¢ä¸Šé…ç½®çš„ DB è·¯å¾„
        target_db_path = self.db_path_entry.get().strip()
        if not target_db_path:
            target_db_path = Config.DB_PATH # å›é€€åˆ°é»˜è®¤
        
        self.log(f"æ­£åœ¨å°è¯•æŒ‚è½½æ•°æ®åº“: {target_db_path} ...")
        
        # 2. æ›´æ–° Connector çš„è·¯å¾„
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åŠ¨æ€ä¿®æ”¹ db_conn å®ä¾‹çš„è·¯å¾„å±æ€§ï¼Œä»¥ä¾¿åç»­æ“ä½œéƒ½é’ˆå¯¹æ–° DB
        self.db_conn.db_path = target_db_path
        
        if not os.path.exists(target_db_path):
            self.log(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {target_db_path}")
            self.db_status_label.config(text=f"çŠ¶æ€: æ–‡ä»¶ä¸å­˜åœ¨", fg="red")
            self.memory_vectors = []
            return

        # 3. è°ƒç”¨ Backend çš„æ–¹æ³•
        # æ­¤æ—¶ db_conn.fetch_all_vectors() å†…éƒ¨ä¼šä½¿ç”¨ self.db_path (ä¹Ÿå°±æ˜¯æˆ‘ä»¬åˆšæ‰è®¾ç½®çš„ target_db_path)
        raw_data = self.db_conn.fetch_all_vectors()
        
        if not raw_data:
            self.log("æŒ‚è½½æˆåŠŸï¼Œä½†æ•°æ®åº“ä¸ºç©º (æ²¡æœ‰æœ‰æ•ˆå‘é‡)ã€‚")
            self.memory_vectors = []
            self.db_status_label.config(text=f"çŠ¶æ€: ç©ºæ•°æ®åº“ | Path: {os.path.basename(target_db_path)}", fg="#ff8800")
            return

        # 4. è½¬æ¢æ•°æ®æ ¼å¼ + å¢å¼ºçš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        self.memory_vectors = []
        skip_count = 0
        
        for item in raw_data:
            try:
                # âœ¨ é¢å¤–çš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
                if not item.get('pure_text') or not item['pure_text'].strip():
                    self.log(f"âš ï¸ è­¦å‘Šï¼šè®°å½• {item['id'][:8]}... ç¼ºå°‘æœ‰æ•ˆçš„ pure_textï¼Œå·²è·³è¿‡")
                    skip_count += 1
                    continue
                
                item['np_vector'] = np.array(item['vector'])
                self.memory_vectors.append(item)
            except Exception as e:
                self.log(f"âš ï¸ è­¦å‘Šï¼šå¤„ç†è®°å½• {item.get('id', 'unknown')[:8]}... æ—¶å‡ºé”™: {e}")
                skip_count += 1
                continue
            
        count = len(self.memory_vectors)
        if skip_count > 0:
            self.log(f"[Info] æ•°æ®åº“æŒ‚è½½æˆåŠŸï¼å·²è·³è¿‡ {skip_count} æ¡æŸåè®°å½•ã€‚")
        self.log(f"[Success] å†…å­˜ç´¢å¼•å·²æ„å»ºï¼Œå…± {count} æ¡æœ‰æ•ˆæ•°æ®å¯ç”¨ã€‚")
        self.db_status_label.config(text=f"çŠ¶æ€: å·²æŒ‚è½½ âœ… | ç´¢å¼•é‡: {count} æ¡", fg="green")

    # --- çº¿ç¨‹å·¥ä½œé€»è¾‘ï¼šå…¥åº“ (JSON -> API -> DB) ---
    def start_ingestion_thread(self):
        path = self.json_path_entry.get()
        if not os.path.exists(path):
            messagebox.showerror("é”™è¯¯", "æ‰¾ä¸åˆ°è¾“å…¥çš„ JSON æ–‡ä»¶")
            return
        
        try:
            batch_size = int(self.batch_size_spin.get())
            max_workers = int(self.concurrency_spin.get())
            if batch_size < 1 or max_workers < 1: raise ValueError
        except:
            messagebox.showerror("é”™è¯¯", "æ‰¹æ¬¡å¤§å°æˆ–å¹¶å‘æ•°å¿…é¡»ä¸ºæ­£æ•´æ•°")
            return

        api_config = self.get_current_api_config()
        
        self.btn_ingest.config(state="disabled")
        self.log(f"å¯åŠ¨å…¥åº“ä»»åŠ¡ | æº: JSON | ç›®æ ‡: DB | å¹¶å‘: {max_workers}")
        
        threading.Thread(
            target=self.run_ingestion, 
            args=(path, api_config, batch_size, max_workers), 
            daemon=True
        ).start()

    def run_ingestion(self, json_path, api_config, batch_size, max_workers):
        """
        âœ¨ æ–¹æ¡ˆ 2 ä¿®å¤ç‰ˆæœ¬ï¼šæ‰¹é‡å…¥åº“é€»è¾‘
        æ ¸å¿ƒæ”¹è¿›ï¼šåœ¨å¤„ç† batch æ—¶ï¼Œä¼˜å…ˆä» JSON çš„ pure_text è¯»å–ï¼Œå®ç°å¤šçº§é™çº§ç­–ç•¥
        """
        try:
            self.log("æ­£åœ¨è§£æ JSON æ–‡ä»¶...")
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            total_items = len(data)
            self.log(f"è§£ææˆåŠŸï¼Œå…± {total_items} æ¡æ•°æ®å¾…å¤„ç†ã€‚")
            
            # æ•°æ®æ£€æŸ¥ï¼šæ‰«æ JSON ä¸­æ˜¯å¦åŒ…å« pure_text å­—æ®µ
            sample_item = data[0] if data else {}
            has_pure_text = 'pure_text' in sample_item
            self.log(f"[Info] JSON æ•°æ®ç»“æ„æ£€æŸ¥ï¼špure_text å­—æ®µ {'âœ… å·²åŒ…å«' if has_pure_text else 'âŒ ç¼ºå¤±'}")
            
            batches = []
            for i in range(0, total_items, batch_size):
                batch_data = data[i:i+batch_size]
                batch_texts = [item['embedding_text'] for item in batch_data]
                batches.append({
                    'index': i,
                    'data': batch_data,
                    'texts': batch_texts
                })
            
            processed_data = []
            processed_count = 0
            lock = threading.Lock()
            
            def process_batch(batch_info):
                """
                âœ¨ æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼šå®ç°æ–¹æ¡ˆ 2 çš„å¤šçº§é™çº§ç­–ç•¥
                """
                texts = batch_info['texts']
                def thread_logger(msg):
                    if "Error" in msg or "error" in msg: 
                        self.log(msg)
                
                try:
                    vectors = self.adapter.get_embeddings(texts, provider_config=api_config, logger=thread_logger)
                    
                    result_records = []
                    for idx, item in enumerate(batch_info['data']):
                        meta = item.get('metadata', {})
                        path_list = meta.get('section_path', [])
                        h1 = path_list[1] if len(path_list) > 1 else ""
                        h2 = path_list[2] if len(path_list) > 2 else ""
                        
                        record = item.copy()
                        record['embedding'] = vectors[idx]
                        record['chapter_title_temp'] = h1
                        record['sub_title_temp'] = h2
                        
                        # âœ¨ æ–¹æ¡ˆ 2 çš„æ ¸å¿ƒä¿®å¤ï¼šå¤šçº§é™çº§ç­–ç•¥è·å– pure_text
                        pure_text = ""
                        
                        # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šç›´æ¥ä» JSON çš„ pure_text å­—æ®µè¯»å–
                        if 'pure_text' in item and item['pure_text']:
                            pure_text = item['pure_text'].strip()
                            
                        # ç¬¬äºŒä¼˜å…ˆçº§ï¼šä» metadata ä¸­è¯»å–
                        elif 'pure_text' in meta and meta['pure_text']:
                            pure_text = meta['pure_text'].strip()
                        
                        # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šä» embedding_text åˆ†å‰²æå–
                        else:
                            embedding_text = item.get('embedding_text', '')
                            if "Content: " in embedding_text:
                                pure_text = embedding_text.split("Content: ", 1)[1].strip()
                            else:
                                pure_text = embedding_text.strip()
                        
                        # æœ€åä¿åº•ï¼šç¡®ä¿ pure_text ä¸ä¸ºç©º
                        if not pure_text:
                            pure_text = item.get('embedding_text', '').strip()
                        
                        # å°†å¤„ç†åçš„ pure_text ä¿å­˜åˆ° metadata å’Œ recordï¼Œä¾›åç»­ bulk_insert ä½¿ç”¨
                        meta['pure_text'] = pure_text
                        record['metadata'] = meta
                        
                        result_records.append(record)
                    return result_records
                except Exception as e:
                    self.log(f"[Batch Error] ç´¢å¼• {batch_info['index']} å¤±è´¥: {e}")
                    return None

            self.log(f"å¼€å§‹å¹¶å‘å¤„ç†ï¼Œçº¿ç¨‹æ± å¤§å°: {max_workers}")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_batch = {executor.submit(process_batch, b): b for b in batches}
                
                for future in concurrent.futures.as_completed(future_to_batch):
                    results = future.result()
                    if results:
                        with lock:
                            # è¿™é‡Œè°ƒç”¨ backend çš„ bulk_insertï¼Œæ•°æ®çœŸæ­£å­˜å…¥ Warehouse (DB)
                            # bulk_insert å†…éƒ¨å·²ç»é›†æˆäº†æ–¹æ¡ˆ 2 çš„é€»è¾‘
                            self.db_conn.bulk_insert(results)
                            processed_data.extend(results)
                            processed_count += len(results)
                            
                            progress = (processed_count / total_items) * 100
                            self.msg_queue.put(("PROGRESS", progress))
                            
                            if processed_count % (batch_size * 2) == 0:
                                self.log(f"è¿›åº¦: {processed_count}/{total_items} å·²å…¥åº“")
            
            self.log("="*50)
            self.log("å…¥åº“ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼æ•°æ®å·²å®‰å…¨å­˜å…¥æ•°æ®åº“ã€‚")
            self.log(f"æ€»å¤„ç†æ•°: {len(processed_data)} | æˆåŠŸç‡: {len(processed_data)/total_items*100:.1f}%")
            self.log("="*50)
            self.msg_queue.put(("STATUS_DONE", f"å…¥åº“æˆåŠŸï¼å…± {len(processed_data)} æ¡æ•°æ®ã€‚\nå·²å­˜å…¥ DBï¼Œready for RAG simulation."))
            
        except Exception as e:
            import traceback
            err = traceback.format_exc()
            self.log(f"FATAL ERROR: {str(e)}")
            print(err)
            self.msg_queue.put(("ERROR", f"ï¿½ï¿½ï¿½ç†å¼‚å¸¸: {str(e)}"))

    # --- ä»¿çœŸæœç´¢é€»è¾‘ (Read from DB Memory) ---
    def run_simulation(self):
        """
        âœ¨ æ–¹æ¡ˆ 2 ä¿®å¤ç‰ˆæœ¬ï¼šRAG ä»¿çœŸæœç´¢
        ä½¿ç”¨ä»æ•°æ®åº“åŠ è½½çš„ã€ç»è¿‡éªŒè¯çš„ pure_text å’Œ full_context_text è¿›è¡Œå¬å›
        """
        query = self.query_entry.get()
        if not query: return
        
        # å¼ºåˆ¶æ£€æŸ¥ï¼šå¿…é¡»åŸºäºæ•°æ®åº“å†…å®¹
        if not self.memory_vectors:
            messagebox.showwarning("è­¦å‘Š", "å½“å‰æœªæŒ‚è½½æ•°æ®åº“æˆ–æ•°æ®åº“ä¸ºç©ºã€‚\nè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å¹¶ç‚¹å‡»'ç«‹å³æŒ‚è½½/åˆ·æ–°'")
            return

        self.result_area.configure(state="normal")
        self.result_area.delete(1.0, tk.END)
        
        api_config = self.get_current_api_config()
        self.log(f"æ­£åœ¨å‘é‡åŒ–é—®é¢˜: '{query}' ...")
        
        try:
            q_vec = self.adapter.get_embeddings([query], provider_config=api_config, logger=None)[0]
            q_vec_np = np.array(q_vec)
        except Exception as e:
            self.result_area.insert(tk.END, f"[Error] å‘é‡åŒ–å¤±è´¥: {e}\n")
            self.log(f"å‘é‡åŒ–å¤±è´¥: {e}")
            return

        self.log(f"æ­£åœ¨ {len(self.memory_vectors)} æ¡æ•°æ®ä¸­æ£€ç´¢ (ä½™å¼¦ç›¸ä¼¼åº¦)...")
        scores = []
        q_norm = np.linalg.norm(q_vec_np)
        
        # è¿™é‡Œçš„ item æ¥æºäº reload_memory_db ä¸­æ‹‰å–çš„ DB æ•°æ®
        for item in self.memory_vectors:
            d_vec_np = item['np_vector']
            d_norm = np.linalg.norm(d_vec_np)
            
            if q_norm == 0 or d_norm == 0:
                sim = 0
            else:
                sim = np.dot(q_vec_np, d_vec_np) / (q_norm * d_norm)
            
            scores.append((sim, item))

        scores.sort(key=lambda x: x[0], reverse=True)
        top_k = scores[:3]

        self.result_area.insert(tk.END, f"\n{'='*20} ä»¿çœŸå¬å›ç»“æœ (Top 3) {'='*20}\n")
        
        current_db_name = os.path.basename(self.db_path_entry.get())
        self.result_area.insert(tk.END, f"æ•°æ®æº: {current_db_name} (Pure Text Fusion - Method 2 Enhanced)\n\n", "source_db")
        
        if not top_k:
            self.result_area.insert(tk.END, "æ— åŒ¹é…ç»“æœã€‚\n")

        for i, (score, item) in enumerate(top_k):
            self.log(f"Top {i+1} Score: {score:.4f} | Doc: {item['doc']}")
            
            self.result_area.insert(tk.END, f"Rank {i+1} | ")
            self.result_area.insert(tk.END, f"ç›¸ä¼¼åº¦: {score:.4f}\n", "score")
            
            # 1. æ ‡é¢˜
            title_text = f"æ–‡æ¡£: {item['doc']} >> ç« : {item['chapter']} >> èŠ‚: {item['sub']}\n"
            self.result_area.insert(tk.END, title_text, "title_hit")
            
            # 2. èåˆå†…å®¹å±•ç¤º (Full Context Header + Pure Text Body)
            # âœ¨ æ–¹æ¡ˆ 2 ä¿®å¤ï¼špure_text ç°åœ¨æ˜¯ç›´æ¥ä»æ•°æ®åº“è¯»å–çš„ã€ç»è¿‡éªŒè¯çš„å€¼
            full_context = item['text']
            pure_text_body = item.get('pure_text', "")
            
            # æå– Header (åŒ…å«è·¯å¾„ä¿¡æ¯çš„éƒ¨åˆ†)
            header_text = ""
            if "Content: " in full_context:
                header_text = full_context.split("Content: ", 1)[0] + "Content: "
            else:
                header_text = "Metadata Header (Parse Failed):"

            # æ˜¾ç¤º Header
            self.result_area.insert(tk.END, f"[Full Context Header]:\n{header_text}\n", "meta")
            
            # æ˜¾ç¤º Body (ä¼˜å…ˆä½¿ç”¨ç»è¿‡éªŒè¯çš„ Pure Text)
            if pure_text_body and len(pure_text_body.strip()) > 0:
                 self.result_area.insert(tk.END, f"[Pure Text Body - DB Source]:\n{pure_text_body.strip()}\n", "pure_body")
            elif "Content: " in full_context:
                 # Fallback (ä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œå¦‚æœæ•°æ®åº“åŠ è½½æ­£å¸¸)
                 fallback_body = full_context.split("Content: ", 1)[1]
                 self.result_area.insert(tk.END, f"[Body (Fallback)]:\n{fallback_body.strip()}\n")
            else:
                 self.result_area.insert(tk.END, f"[Body]:\n{full_context}\n")

            self.result_area.insert(tk.END, "-"*50 + "\n")

        self.result_area.configure(state="disabled")

if __name__ == "__main__":
    root = tk.Tk()
    app = RAGSimulatorGUI(root)
    root.mainloop()